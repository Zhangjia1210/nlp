{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Контекстно-независимое векторное представление слов\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\张佳\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    business       0.00      0.00      0.00        79\n",
      "     culture       0.59      0.61      0.60       279\n",
      "   economics       0.62      0.86      0.72       266\n",
      "      forces       0.54      0.51      0.53       149\n",
      "        life       0.68      0.55      0.61       288\n",
      "       media       0.55      0.68      0.61       299\n",
      "     science       0.60      0.66      0.63       288\n",
      "       sport       0.86      0.88      0.87       276\n",
      "       style       0.89      0.21      0.34        38\n",
      "      travel       0.00      0.00      0.00        38\n",
      "\n",
      "    accuracy                           0.64      2000\n",
      "   macro avg       0.53      0.49      0.49      2000\n",
      "weighted avg       0.61      0.64      0.61      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\张佳\\source\\repos\\nlp\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\张佳\\source\\repos\\nlp\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\张佳\\source\\repos\\nlp\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import gzip\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from typing import List\n",
    "\n",
    "# Loading texts\n",
    "def read_texts(fn: str) -> List[str]:\n",
    "    texts = []\n",
    "    labels = []\n",
    "    with gzip.open(fn, \"rt\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(\"\\t\")\n",
    "            labels.append(parts[0])\n",
    "            texts.append(parts[2])\n",
    "    return labels, texts\n",
    "\n",
    "labels, texts = read_texts(\"news.txt.gz\")  \n",
    "\n",
    "# Text preprocessing\n",
    "def preprocess_text(text: str) -> list:\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\(.*?\\)', '', text)\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    stop_words = set(stopwords.words('russian'))\n",
    "    words = word_tokenize(text)\n",
    "    words = [word for word in words if word.isalpha() and word not in stop_words]\n",
    "    return words\n",
    "\n",
    "processed_texts = [preprocess_text(text) for text in tqdm(texts, disable=True)]\n",
    "\n",
    "# Separation into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(processed_texts, labels, test_size=0.2, random_state=42)\n",
    "model = Word2Vec(sentences=X_train, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "def document_vector(model, words):\n",
    "    vectors = [model.wv[word] for word in words if word in model.wv]\n",
    "    if not vectors:\n",
    "        return None\n",
    "    return sum(vectors) / len(vectors)\n",
    "\n",
    "X_train_vectors = [document_vector(model, words) for words in X_train]\n",
    "X_test_vectors = [document_vector(model, words) for words in X_test]\n",
    "\n",
    "X_train_vectors = [vec for vec in X_train_vectors if vec is not None]\n",
    "y_train = [label for vec, label in zip(X_train_vectors, y_train) if vec is not None]\n",
    "X_test_vectors = [vec for vec in X_test_vectors if vec is not None]\n",
    "y_test = [label for vec, label in zip(X_test_vectors, y_test) if vec is not None]\n",
    "\n",
    "# SVM Training\n",
    "classifier = SVC(kernel='linear')\n",
    "classifier.fit(X_train_vectors, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test_vectors)\n",
    "\n",
    "# Evaluating the results\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
